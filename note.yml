{
  "owner": "radicaldo",
  "repo": "sownd",
  "branch": "master",
  "message": "Add initial architecture, graph spec, and roadmap docs",
  "files": [
    {
      "path": "README.md",
      "content": "# sownd\n\nAV Production Automation Platform\n\n`sownd` is a developer-first, modular **audio + MIDI + automation + networking** platform.\n\nThink: a software-defined patchbay for music/AV production workflows.\n\n- Drag/drop node graph for routing audio/events/MIDI/HTTP/WebSocket/OSC\n- “Companion mode” control surfaces (buttons/faders/pages) with feedback\n- Headless runner + Hub APIs so graphs can run locally or on a network node\n- LLM-assisted authoring (patterns/patches) with strict validation and preview\n\n## What sownd is (and is not)\n\n**Is:** a programmable audio automation and networking engine with a slick graph UI.\n\n**Not (v1):** a full timeline DAW replacement.\n\n## Core ideas\n\n- **Two worlds:**\n  - **Realtime**: audio + sample-accurate scheduling (no blocking/await)\n  - **Automation**: HTTP/files/LLM/webhooks/retries (observable, resilient)\n- **Everything is a node:** typed ports + JSON-serializable state.\n- **LLM proposes, compiler validates:** no direct arbitrary execution.\n\n## Docs\n\n- docs/ARCHITECTURE.md\n- docs/GRAPH_SPEC.md\n- docs/SOW.md\n- docs/AI_AUDIO_STACK.md\n- docs/SECURITY_MODEL.md\n- ROADMAP.md\n\n## Suggested MVP scope\n\nA compelling MVP can be built around:\n- Graph editor + save/load + undo/redo\n- Transport (play/stop/BPM) + event scheduler\n- 10–12 core nodes (Pattern/Clock/Synth/Sampler/FX/MIDI/HTTP/WS/OSC/Recorder)\n- Local Hub API (REST + WebSocket events)\n\n## License\n\nSee LICENSE.\n"
    },
    {
      "path": "ROADMAP.md",
      "content": "# sownd roadmap\n\nThis is a practical, buildable roadmap that gets to a compelling demo quickly while keeping a clean path to “serious” engine work.\n\n## Phase 0 — Spec + scaffolding (days)\n- Lock graph JSON format + versioning\n- Choose UI graph framework and IPC\n- Establish repo layout and contribution conventions\n\n## Phase 1 — Patchbay MVP (weeks)\n- Graph editor (palette, inspector, cables, undo/redo)\n- Transport + deterministic event scheduling\n- Basic audio output (one synth + gain/meter + master)\n- MIDI in/out routing\n- Local Hub API: REST + WebSocket event stream\n\n## Phase 2 — Automation + companion mode (weeks)\n- Actions/bindings/feedback model\n- Control surface pages (buttons/faders)\n- Nodes for HTTP/WS/OSC triggers and outputs\n- “Satellite” clients for remote control\n\n## Phase 3 — Recording + looping + clips (weeks)\n- Recorder node (buses to file)\n- Loop node (record/quantize/loop)\n- Scene/clip launcher\n\n## Phase 4 — AI assist (weeks)\n- Offline ASR for commands (Whisper family)\n- Local LLM authoring (Ollama) for patterns and graph patches\n- Guardrails: schema validation + preview/diff + safe apply\n\n## Phase 5 — Beatboxing/humming to tracks (R&D)\n- Audio→features→events pipelines (onsets, pitch, classification)\n- MIDI export + sample mapping + groove templates\n- Optional separation-first workflows (stems)\n"
    },
    {
      "path": "docs/ARCHITECTURE.md",
      "content": "# sownd architecture (achievable)\n\n## North-star\n\nA developer-first audio automation platform that feels like a DAW-adjacent patchbay:\n\n- Graph-based routing for audio + events + MIDI + OSC + HTTP/WebSocket\n- Runs locally or as a network hub\n- Extensible node/plugin model\n- Realtime-safe where it matters, observable everywhere\n\n## Design rules (non-negotiable)\n\n1. **Two worlds**\n   - **Realtime world**: audio + sample-accurate scheduling. No blocking, no I/O, bounded allocations.\n   - **Automation world**: HTTP, file I/O, LLM calls, device discovery, macros, retries.\n2. **Typed ports** and **JSON-serializable state** for every node.\n3. **LLM proposes, compiler validates**: LLM output must be schema-valid and previewable.\n4. **One graph spec** shared by UI, local runner, and hub.\n\n## Components\n\n### 1) UI app\nDesktop-first (recommended): Tauri shell hosting a web UI.\n\nUI responsibilities:\n- Node graph editor + inspector\n- Control surface pages (buttons/faders/meters)\n- Project management (save/load, assets)\n- Observability views (event log, node stats, jitter meters)\n\n### 2) Realtime engine\nThe realtime engine owns audio rendering and tightly scheduled musical events.\n\nImplementation options:\n- **MVP**: Web Audio + AudioWorklet (inside the app WebView)\n- **Upgrade**: native audio sidecar (Rust/C++), UI talks over IPC/WebSocket/gRPC\n\nRealtime responsibilities:\n- Audio graph processing (DSP nodes)\n- Event scheduling with deterministic timing\n- Realtime-safe bridge from automation → realtime\n\n### 3) Automation engine (ETL/orchestration)\nRuns asynchronous nodes and long-running tasks.\n\nResponsibilities:\n- HTTP/WS/OSC integrations\n- file operations, asset indexing\n- recording management\n- LLM + ASR/TTS service calls\n- retries, rate limits, credentials\n- structured event log and metrics\n\n### 4) Hub (network runtime)\nThe hub hosts graphs and exposes APIs so sownd can act like a network appliance.\n\nResponsibilities:\n- Graph deployment/run/stop\n- client sessions, auth, permissions\n- shared transport/clock (optional)\n- device/satellite registry\n\n## Data model\n\n- **Project**: graphs + assets + presets + bindings\n- **Graph**: nodes + edges + transport config\n- **Node**: type + params + runtime state + UI state\n- **Edge**: typed connection from port → port\n\n## “Companion mode” model\n\n- **Actions**: invokable operations (trigger scene, toggle node, set param)\n- **Bindings**: map input (MIDI/OSC/UI button/HTTP) → action\n- **Feedback**: state updates (LED color/label/meter)\n\n## Why this works\n\n- Realtime stays deterministic and small.\n- Automation stays powerful without breaking audio.\n- The graph spec becomes the product surface: saveable, shareable, API-run.\n"
    },
    {
      "path": "docs/GRAPH_SPEC.md",
      "content": "# sownd graph spec (v0.1 draft)\n\nThis document defines the portable graph format and runtime interfaces.\n\n## Graph JSON\n\nHigh-level shape:\n\n- `version`: string (e.g., \"0.1\")\n- `transport`: `{ bpm, timeSignature, swing, scene }`\n- `nodes`: `Node[]`\n- `edges`: `Edge[]`\n- `assets`: `Asset[]`\n\n### Node\n\nRequired:\n- `id`: string (stable UUID)\n- `type`: string (e.g., \"audio.synth.basic\")\n- `params`: object (schema-defined)\n\nOptional:\n- `state`: object (runtime-managed; should be persistable when safe)\n- `ui`: object (position, collapsed, color, etc.)\n\n### Edge\n\n- `id`: string\n- `from`: `{ nodeId, port }`\n- `to`: `{ nodeId, port }`\n- `type`: one of the port types (below)\n\n## Port types\n\n- `audio`: realtime audio stream\n- `event`: timestamped musical events (note/cc/automation)\n- `midi`: raw MIDI bytes or structured packets\n- `control`: parameter/control messages\n- `http`: request/response or webhook payloads\n- `ws`: websocket messages\n- `osc`: OSC messages\n- `text`: prompts, transcripts, code\n- `blob`: file chunks / binary assets\n\n## Event model\n\nCanonical event envelope:\n\n- `t`: time (transport-relative or sample-time; must be consistent per runtime)\n- `kind`: string (e.g., \"noteOn\", \"noteOff\", \"cc\", \"param\")\n- `data`: object\n- `source`: `{ nodeId, port }`\n\nRealtime delivery:\n- automation → realtime uses a bounded queue\n- backpressure policy must be explicit (drop oldest/newest, throttle, etc.)\n\n## Node manifests (plugin metadata)\n\nEach node type ships a manifest:\n\n- `type`: string\n- `name`: string\n- `version`: semver\n- `ports`: `{ inputs: PortDef[], outputs: PortDef[] }`\n- `paramsSchema`: JSON Schema\n- `capabilities`: e.g., `filesystem`, `network`, `midi`, `microphone`\n\n## Runtime interfaces\n\n### Realtime nodes\n\n- must be deterministic\n- no blocking, no network/files\n- bounded memory behavior\n\n### Task nodes (automation)\n\n- async execution allowed\n- should emit structured logs + progress\n- should be restartable/idempotent where possible\n\n## Versioning\n\n- Graph JSON version is required.\n- Node manifests are semver and should remain backwards compatible when possible.\n- Provide migration tooling for graph versions.\n"
    },
    {
      "path": "docs/SOW.md",
      "content": "# sownd SOW (statement of work)\n\nThis is a practical scope outline for building sownd in phases.\n\n## Vision\n\nBuild a modular audio automation + networking platform with a drag/drop node graph, companion-style control surfaces, and developer-first APIs.\n\n## Deliverables\n\n### D0: Specification + scaffolding\n- Graph spec v0.1\n- Repo layout and dev scripts\n- Minimal UI shell with graph canvas loading a sample graph\n\n### D1: Patchbay MVP\n- Graph editor: palette, inspector, connect ports, save/load, undo/redo\n- Transport: play/stop, BPM\n- Realtime output: synth + gain/meter + master\n- MIDI routing: in/out\n- Local Hub API: REST + WebSocket events\n\nAcceptance criteria:\n- Can build a graph that makes sound, routes MIDI, and persists.\n- Playback stable for 30+ minutes with visible jitter metrics.\n\n### D2: Automation + companion mode\n- Actions/bindings/feedback model\n- Control surface UI (buttons/faders/pages)\n- Nodes: HTTP trigger, WebSocket trigger, OSC out, timers/schedulers\n- “Satellite” clients can connect and control graphs\n\nAcceptance criteria:\n- Any action invokable via API.\n- Feedback updates are consistent and debuggable.\n\n### D3: Recording/looping/clips\n- Recorder node (bus capture to file)\n- Loop node (record → quantize → loop)\n- Scene/clip launcher\n\nAcceptance criteria:\n- Looping stays in sync with transport.\n\n### D4: AI assist\n- Offline ASR for commands\n- Local LLM assisted authoring\n- Guardrails: schema validation, preview/diff, safe apply\n\nAcceptance criteria:\n- AI can’t crash realtime engine.\n- All AI operations leave an audit trail.\n\n## Risks and mitigations\n\n- **Realtime stability**: isolate realtime runtime; measure jitter; avoid main-thread load.\n- **Cross-platform device I/O**: desktop-first shell; provide fallbacks; document support.\n- **Plugin surface sprawl**: keep node types few and composable early.\n- **AI hallucinations**: strict schemas + “propose then apply” workflow.\n"
    },
    {
      "path": "docs/AI_AUDIO_STACK.md",
      "content": "# AI + audio stack (open source) for sownd\n\nThis is a curated list of practical OSS components for voice/text/audio-to-events workflows.\n\n## Speech-to-text (ASR)\n\n- Whisper family\n  - whisper.cpp (MIT): https://github.com/ggml-org/whisper.cpp\n    - fast, embeddable, works offline, good for desktop apps\n  - faster-whisper (MIT): https://github.com/SYSTRAN/faster-whisper\n    - efficient Python inference, good for services\n\nRecommended sownd usage:\n- Voice commands → intent JSON → actions/bindings (automation world)\n\n## Text-to-speech (TTS)\n\n- Piper (local neural TTS)\n  - archived repo: https://github.com/rhasspy/piper\n  - development moved (noted in README): https://github.com/OHF-Voice/piper1-gpl\n\n- Coqui TTS (training + models)\n  - https://github.com/coqui-ai/TTS\n\nRecommended sownd usage:\n- Speak feedback (“armed”, “recording”, “scene 2”) and assistive UX.\n\n## Audio → MIDI / notes\n\n- Basic Pitch (Apache-2.0)\n  - https://github.com/spotify/basic-pitch\n  - audio-to-MIDI with pitch bends; strong practical default\n\nRecommended sownd usage:\n- humming/monophonic lines → MIDI clips\n- quick “turn this into notes” workflows\n\n## Beatboxing / tapping → drums (realistic approach)\n\nThere is no single universally dominant OSS model that perfectly converts beatboxing into multi-track drums in all conditions.\n\nA buildable pipeline:\n1) onset/transient detection (find hit times)\n2) classify hit type (kick/snare/hat/other)\n3) quantize to transport + groove template\n4) map to drum kit + humanize velocity\n\nStart with (1)+(3)+(4) for MVP, add (2) as R&D.\n\n## Source separation (optional but very useful)\n\n- Demucs (MIT; archived upstream with a maintained fork noted)\n  - https://github.com/facebookresearch/demucs\n\nRecommended sownd usage:\n- separate stems before transcription (vocals vs drums vs bass)\n\n## MIR feature extraction (tempo, beats, onsets)\n\n- Essentia (AGPL-3.0)\n  - https://github.com/MTG/essentia\n\nNote on licensing:\n- AGPL can be incompatible with some distribution plans; evaluate early.\n\n## Suggested “Audio→Clip” node recipes\n\n- Record mic → VAD → segment → (Basic Pitch) → MIDI clip\n- Record beatbox → onset detect → quantize → drum clip\n- Record loop → separation → transcribe lead → keep drum stem as audio loop\n"
    },
    {
      "path": "docs/SECURITY_MODEL.md",
      "content": "# sownd security model (v0.1)\n\n## Goals\n\n- Keep realtime engine stable and safe.\n- Make automation powerful without letting it become arbitrary remote code execution.\n- Provide clear permissions for nodes (developer-first, not “mystery behavior”).\n\n## Key rules\n\n1) Realtime nodes never do network/filesystem.\n2) Automation nodes declare capabilities (permissions).\n3) LLM output is treated as untrusted input.\n\n## Capabilities (examples)\n\n- `network.http`\n- `network.websocket`\n- `network.osc`\n- `filesystem.read`\n- `filesystem.write`\n- `device.midi`\n- `device.microphone`\n\nNodes must declare required capabilities. The runtime can prompt/deny.\n\n## LLM safety\n\n- LLM only generates:\n  - graph patches (JSON)\n  - pattern snippets (text)\n- All patches must validate against schemas.\n- Apply flow is always: propose → diff/preview → user confirm → apply.\n- Keep an audit log of prompts and applied patches.\n\n## Network safety\n\n- Hub API requires auth by default in non-local mode.\n- Provide a read-only mode for dashboards.\n- Rate limit event-producing endpoints.\n"
    }
  ]
}